{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from copy import deepcopy\n",
    "import utils\n",
    "\n",
    "def reduce_var(x, axis=None, keepdims=False):\n",
    "    \"\"\"Variance of a tensor, alongside the specified axis.\n",
    "\n",
    "    # Arguments\n",
    "        x: A tensor or variable.\n",
    "        axis: An integer, the axis to compute the variance.\n",
    "        keepdims: A boolean, whether to keep the dimensions or not.\n",
    "            If `keepdims` is `False`, the rank of the tensor is reduced\n",
    "            by 1. If `keepdims` is `True`,\n",
    "            the reduced dimension is retained with length 1.\n",
    "\n",
    "    # Returns\n",
    "        A tensor with the variance of elements of `x`.\n",
    "    \"\"\"\n",
    "    m = tf.reduce_mean(x, axis=axis, keep_dims=True)\n",
    "    devs_squared = tf.square(x - m)\n",
    "    return tf.reduce_mean(devs_squared, axis=axis, keep_dims=keepdims)\n",
    "\n",
    "def reduce_std(x, axis=None, keepdims=False):\n",
    "    \"\"\"Standard deviation of a tensor, alongside the specified axis.\n",
    "\n",
    "    # Arguments\n",
    "        x: A tensor or variable.\n",
    "        axis: An integer, the axis to compute the standard deviation.\n",
    "        keepdims: A boolean, whether to keep the dimensions or not.\n",
    "            If `keepdims` is `False`, the rank of the tensor is reduced\n",
    "            by 1. If `keepdims` is `True`,\n",
    "            the reduced dimension is retained with length 1.\n",
    "\n",
    "    # Returns\n",
    "        A tensor with the standard deviation of elements of `x`.\n",
    "    \"\"\"\n",
    "    return tf.sqrt(reduce_var(x, axis=axis, keepdims=keepdims))\n",
    " \n",
    "TRAIN_DIR = 'C:/Jupyter_project/DL/trainingSet/'\n",
    "x_train = []\n",
    "img_list = os.listdir(TRAIN_DIR)\n",
    "for img_n in img_list:\n",
    "    img_path = os.path.join(TRAIN_DIR, img_n)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    x_train.append([np.array(img)])\n",
    "x_train = np.array(x_train).astype(np.float32)\n",
    "x_train = x_train / 255.0\n",
    "x_train = np.reshape(x_train, (-1,200,200,1))\n",
    "\n",
    "TEST_DIR = 'C:/Jupyter_project/DL/testSet/'\n",
    "x_test = []\n",
    "img_list = os.listdir(TEST_DIR)\n",
    "for img_n in img_list:\n",
    "    img_path = os.path.join(TEST_DIR, img_n)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    x_test.append([np.array(img)])\n",
    "x_test = np.array(x_test).astype(np.float32)\n",
    "x_test = x_test / 255.0\n",
    "x_test = np.reshape(x_test, (-1,200,200,1))\n",
    "\n",
    "#np.save(\"train_data.npy\", x_train)\n",
    "#np.save(\"test_input.npy\",x_test)\n",
    "\n",
    "# this line should be commented out for regular python run \n",
    "%matplotlib inline  \n",
    "# this line should be commented out for regular python run \n",
    "\n",
    "\n",
    "\"\"\" Hyperparameter \"\"\"\n",
    "data_size_train = 1100\n",
    "data_size_test = 230\n",
    "batch_size = 1\n",
    "lr = 1e-6\n",
    "epoch = int(10)\n",
    "\n",
    "\n",
    "\"\"\" Data Loading \"\"\"\n",
    "\n",
    "data = (x_train, x_test)\n",
    "#x_train, x_test = data\n",
    "\n",
    "\n",
    "\"\"\" Graph Construction \"\"\"\n",
    "tf.random.set_random_seed(325)\n",
    "\n",
    "# placeholders\n",
    "x = tf.placeholder(tf.float32, shape=(None, 200, 200, 1), name='x')\n",
    "\n",
    "# weights and layers #################################################################\n",
    "\n",
    "# convolution layer 1\n",
    "# input and input.shape:   x,     (None, 200, 200, 1)\n",
    "# output and output.shape: conv1, (None, 100, 100, 32)\n",
    "conv1_W = tf.get_variable(\"conv1_W\", \\\n",
    "                          shape=(3,3,1,32), \\\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "            #conv:마스크 W로 필터링  #가운데 1두개는 옆으로 한칸씩 움직인다는것\n",
    "conv1 = tf.nn.conv2d(x, conv1_W, strides=(1,1,1,1), \\\n",
    "                     padding='SAME') # (None, 200, 200, 32)\n",
    "\n",
    "#relu: 양수면 양수 그대로를, 음수면 0을 아웃풋                    \n",
    "conv1 = tf.nn.relu(conv1) # (None, 200, 200, 32)\n",
    "# max_pool: 2*2에서 각 구역의 최대점을 output\n",
    "conv1 = tf.nn.max_pool(conv1, ksize=(1,2,2,1), strides=(1,2,2,1), \\\n",
    "                       padding='SAME') # (None, 100, 100, 32)\n",
    "\n",
    "# convolution layer 2\n",
    "# input and input.shape:   conv1, (None, 100, 100 32)\n",
    "# output and output.shape: conv2, (None, 50, 50, 64)\n",
    "conv2_W = tf.get_variable(\"conv2_W\", \\\n",
    "                          shape=(3,3,32,64), \\\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "conv2 = tf.nn.conv2d(conv1, conv2_W, strides=(1,1,1,1), \\\n",
    "                     padding='SAME') # (None, 50, 50, 64)\n",
    "conv2 = tf.nn.relu(conv2) # (None, 50, 50, 64)\n",
    "conv2 = tf.nn.max_pool(conv2, ksize=(1,2,2,1), strides=(1,2,2,1), \\\n",
    "                       padding='SAME') # (None, 50, 50, 64)\n",
    "\n",
    "# fully connected layer\n",
    "# input and input.shape:   conv2, (None, 50, 50, 64)\n",
    "# output and output.shape: fc,    (None, 256) \n",
    "flatten = tf.reshape(conv2, (-1, 160000)) # (None, 50*50*64=160000) \n",
    "fc_W = tf.get_variable(\"fc_W\", \\\n",
    "                        shape=(160000,256), \\\n",
    "                        initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "fc = tf.matmul(flatten, fc_W) # (None, 256) \n",
    "fc = tf.nn.relu(fc) # (None, 256) \n",
    "\n",
    "# output layer\n",
    "# input and input.shape:   fc,     (None, 256) \n",
    "# output and output.shape: logits, (None, 10) \n",
    "out_W = tf.get_variable(\"out_W\", \\\n",
    "                        shape=(256, 1), \\\n",
    "                        initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "cnnout_x = fc @ out_W # (None, 1)\n",
    "\n",
    "outx_mean = tf.reduce_mean(tf.cast(cnnout_x, tf.float32))\n",
    "outx_std = reduce_std(tf.cast(cnnout_x, tf.float32))\n",
    "cnnout_x = (cnnout_x-outx_mean) / outx_std\n",
    "\n",
    "# weights and layers #################################################################\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "df = pd.read_csv('stiffness_training.csv')\n",
    "if 0:\n",
    "    # not good\n",
    "    pass\n",
    "elif 1:\n",
    "    # good\n",
    "    df = (df-df.mean()) / df.std()\n",
    "y_train = df.stiffness.values.astype(np.float32).reshape((-1,1)) # (894,1)\n",
    "\n",
    "df2 = pd.read_csv('stiffness_test.csv')\n",
    "if 0:\n",
    "    # not good\n",
    "    pass\n",
    "elif 1:\n",
    "    # good\n",
    "    df2 = (df2-df2.mean()) / df2.std()\n",
    "y_test = df2.stiffness.values.astype(np.float32).reshape((-1,1)) # (224,1)\n",
    "\n",
    "y = tf.placeholder(tf.float32, shape=(None,1)) # (894,1)\n",
    "\n",
    "alpha = tf.get_variable('alpha', (), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "beta = tf.get_variable('beta', (1,1), dtype=tf.float32, initializer=tf.keras.initializers.constant(0.0))\n",
    "\n",
    "y_pred = alpha + cnnout_x @ beta # (None,1) = () + (None,1) @ (1,1)\n",
    "loss = tf.nn.l2_loss(y-y_pred)\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "# test accuracy\n",
    "error = tf.abs(y-y_pred)\n",
    "error_ratio = tf.divide(error,y)\n",
    "test_accuracy = tf.reduce_mean(tf.cast(error_ratio, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    alpha_trace = []\n",
    "    beta_trace = []\n",
    "    loss_trace = []\n",
    "    \n",
    "    feed_dict = {x:x_train, y:y_train}\n",
    "    for i in range(epoch):\n",
    "        if i == 0:\n",
    "            alpha_run, beta_run, loss_run = sess.run([alpha, beta, loss], feed_dict=feed_dict)\n",
    "        else:\n",
    "            alpha_run, beta_run, loss_run, _ = sess.run([alpha, beta, loss, train], feed_dict=feed_dict)\n",
    "        alpha_trace.append(alpha_run)\n",
    "        beta_trace.append(beta_run[0,0])\n",
    "        loss_trace.append(loss_run)\n",
    "    y_pred_run = sess.run(y_pred, feed_dict=feed_dict)\n",
    "            \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    ax1.plot(alpha_trace)\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.set_title('alpha')\n",
    "    ax2.plot(beta_trace)\n",
    "    ax2.set_xlabel('epoch')\n",
    "    ax2.set_title('beta')\n",
    "    ax3.plot(loss_trace)\n",
    "    ax3.set_xlabel('epoch')\n",
    "    ax3.set_title('loss')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    #fig, ax = plt.subplots(1, 1)\n",
    "    #ax.plot(cox_temp.reshape((-1,)), y_train.reshape((-1,)), 'o')\n",
    "    #ax.plot(cox_temp.reshape((-1,)), yp_temp.reshape((-1,)))\n",
    "    #plt.show()\n",
    "    \n",
    "    # compute test accuracy\n",
    "    test_accuracy_list = []\n",
    "    feed_dict = {x: x_test, y: y_test}\n",
    "    test_accuracy_temp = sess.run(test_accuracy, feed_dict=feed_dict)\n",
    "    test_accuracy_list.append(test_accuracy_temp)\n",
    "    \n",
    "    print('Test Mean Error: ', np.mean(np.array(test_accuracy_list)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
